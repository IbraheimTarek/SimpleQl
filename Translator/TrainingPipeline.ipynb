{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff340bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from farasa.pos import FarasaPOSTagger\n",
    "import torch.nn.init as init\n",
    "from DataSetClass import Parallel_Data\n",
    "from Preprocessing import Preprocessor\n",
    "from model import Encoder, Decoder, Seq2Seq\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058975c3",
   "metadata": {},
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Parallel_Data(\"./preprocessed_train_data.pkl\",\"./arabic_tokens.json\",\"./english_tokens.json\")\n",
    "val_data = Parallel_Data(\"./preprocessed_val_data.pkl\",\"./arabic_tokens.json\",\"./english_tokens.json\")\n",
    "test_data = Parallel_Data(\"./preprocessed_test_data.pkl\",\"./arabic_tokens.json\",\"./english_tokens.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7770f2a",
   "metadata": {},
   "source": [
    "## Weight initialization using xavier to put the model on a good starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7834e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    # LSTM layers\n",
    "    if isinstance(module, nn.LSTM):\n",
    "        for name, param in module.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "                # Set forget-gate bias to 1\n",
    "                n = param.size(0)\n",
    "                start, end = n // 4, n // 2\n",
    "                param.data[start:end].fill_(1)\n",
    "\n",
    "    # Vanilla RNN/GRU layers\n",
    "    elif isinstance(module, (nn.RNN, nn.GRU)):\n",
    "        for name, param in module.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "\n",
    "    # Linear layers (used in attention and decoder output)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        init.xavier_uniform_(module.weight.data)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec7c82",
   "metadata": {},
   "source": [
    "## model parameters and data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ee2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_arabic = len(train_data.arabic_tokens)\n",
    "input_dim_postag = len(train_data.postags)\n",
    "OUTPUT_DIM = len(train_data.english_tokens)\n",
    "\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data,32,shuffle=True)\n",
    "val_dataloader = DataLoader(val_data,256,shuffle=False)\n",
    "test_dataloader = DataLoader(train_data,256,shuffle=False)\n",
    "\n",
    "enc_arabic = Encoder(input_dim_arabic, ENC_EMB_DIM, HID_DIM, N_LAYERS,device)\n",
    "enc_postag = Encoder(input_dim_postag, 128, HID_DIM, N_LAYERS,device)\n",
    "\n",
    "dec = Decoder(\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    emb_dim=DEC_EMB_DIM,\n",
    "    hid_dim=HID_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    enc_hid_dim=HID_DIM * 4,  \n",
    "    attn_dim=64\n",
    ")\n",
    "\n",
    "enc_arabic.apply(init_weights)\n",
    "enc_postag.apply(init_weights)\n",
    "dec.apply(init_weights)\n",
    "\n",
    "model = Seq2Seq(enc_arabic, enc_postag, dec, device).to(device)\n",
    "\n",
    "\n",
    "token_counts = torch.zeros(len(train_data.english_tokens), dtype=torch.long)\n",
    "\n",
    "\n",
    "for _,trg_batch,_,_ in train_dataloader:\n",
    "    trg = trg_batch.to(\"cpu\") \n",
    "    token_counts += torch.bincount(\n",
    "        trg.flatten(), minlength=len(train_data.english_tokens)\n",
    "    )\n",
    "\n",
    "token_counts[0] = 0\n",
    "\n",
    "weights = 1.0 / torch.sqrt(token_counts.float() + 1e-5)\n",
    "weights[0] = 0  \n",
    "weights[-1] = 0\n",
    "weights = weights / weights.mean()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=weights.to(device),\n",
    "    ignore_index=0,      \n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.5,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7ff4c",
   "metadata": {},
   "source": [
    "# attention plotter to monitor heat map changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829da3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def plot_attention(attention, source_tokens, target_tokens, epoch=None, filename=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    cax = ax.matshow(attention, cmap='viridis')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticks(np.arange(len(source_tokens)))\n",
    "    ax.set_yticks(np.arange(len(target_tokens)))\n",
    "    ax.set_xticklabels(source_tokens, rotation=90)\n",
    "    ax.set_yticklabels(target_tokens)\n",
    "\n",
    "    # Force label every token\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.title(f\"Attention Weights (Epoch {epoch})\" if epoch else \"Attention Weights\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd8802",
   "metadata": {},
   "source": [
    "## Train and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08580d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()  \n",
    "    epoch_loss = 0\n",
    "    for src, trg, src_length , postags in dataloader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        postags = postags.to(device)\n",
    "        src_length = src_length.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        output, _ = model(src, trg,src_length, postags, teacher_forcing_ratio = 0.5)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()  \n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    print(\"done\")\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion,epoch, return_attention ,sample_index=0):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            src, trg, src_len, postags = batch\n",
    "            src_len = src_len.to(device)\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            postags = postags.to(device)\n",
    "    \n",
    "            output, attentions  = model(src, trg, src_len, postags, teacher_forcing_ratio = 0,return_attentions = return_attention)\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg_flat = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg_flat)\n",
    "            epoch_loss += loss.item()\n",
    "              \n",
    "\n",
    "    if i == len(dataloader) - 1 and attentions:\n",
    "        # Convert to numpy and select sample\n",
    "        attn_matrix = torch.stack(attentions).squeeze(1)[:, sample_index, :]\n",
    "        sample_attentions = attn_matrix.numpy()\n",
    "             \n",
    "    inv_src_vocab = {i: w for w, i in train_data.arabic_tokens.items() }\n",
    "    inv_trg_vocab = {i: w for w, i in train_data.english_tokens.items() }\n",
    "\n",
    "    src_tokens = [inv_src_vocab[idx] for idx in src[sample_index].cpu().numpy() \n",
    "                 if idx not in [0, train_data.arabic_tokens[\"<s>\"], train_data.arabic_tokens[\"</s>\"]]]  \n",
    "\n",
    "    trg_tokens = [inv_trg_vocab[idx] for idx in trg[sample_index].cpu().numpy() \n",
    "                 if idx not in [0, train_data.english_tokens[\"<s>\"], train_data.english_tokens[\"</s>\"]]]\n",
    "    \n",
    "    if sample_attentions is not None:\n",
    "        plot_filename = f\"attention_epoch_{epoch}.png\"\n",
    "        plot_attention(\n",
    "            sample_attentions, \n",
    "            source_tokens=src_tokens,\n",
    "            target_tokens=trg_tokens,\n",
    "            epoch=epoch,\n",
    "            filename=plot_filename\n",
    "        )\n",
    "    model.train()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a197188",
   "metadata": {},
   "source": [
    "# Evaluation and Inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "import torch\n",
    "\n",
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "smooth_fn = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d3387",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a62fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,src, src_length, postags, max_length, start_index, end_index):\n",
    "        batch_size = src.size(0)\n",
    "        device = src.device\n",
    "        \n",
    "        # Encode source sequences\n",
    "        enc_outs_arabic, hidden_arabic, cell_arabic = model.encoder_arabic(src, src_length)\n",
    "        enc_outs_postag, hidden_postag, cell_postag = model.encoder_postag(postags, src_length)\n",
    "        \n",
    "        # Combine encoder outputs\n",
    "        combined_enc_outs = torch.cat((enc_outs_arabic, enc_outs_postag), dim=2)\n",
    "        max_src_len = combined_enc_outs.size(1)\n",
    "        \n",
    "        # Create mask from source lengths\n",
    "        mask = model.create_mask(src_length, max_src_len)\n",
    "        \n",
    "        # Initialize decoder states\n",
    "        hidden = model.enc2dec(torch.cat((hidden_arabic, hidden_postag), dim=2))\n",
    "        cell = model.enc2dec(torch.cat((cell_arabic, cell_postag), dim=2))\n",
    "        \n",
    "        # Initialize output tensor with SOS tokens\n",
    "        output_ids = torch.full((batch_size, max_length), eos_index, dtype=torch.long, device=device)\n",
    "        output_ids[:, 0] = sos_index\n",
    "        \n",
    "        # Track finished sequences\n",
    "        unfinished = torch.ones(batch_size, dtype=torch.bool, device=device)\n",
    "        \n",
    "        # Track which sequences are active in current step\n",
    "        active_mask = torch.arange(batch_size, device=device)\n",
    "        \n",
    "        # Autoregressive generation\n",
    "        for t in range(1, max_length):\n",
    "            # Get last predicted tokens for active sequences\n",
    "            input = output_ids[active_mask, t-1]  # [current_batch_size]\n",
    "            \n",
    "            # Run decoder for active sequences\n",
    "            decoder_output, hidden_step, cell_step, _ = model.decoder(\n",
    "                input=input,\n",
    "                hidden=hidden[:, active_mask, :],\n",
    "                cell=cell[:, active_mask, :],\n",
    "                encoder_outputs=combined_enc_outs[active_mask],\n",
    "                mask=mask[active_mask]\n",
    "            )\n",
    "            \n",
    "            # Greedy token selection\n",
    "            next_tokens = decoder_output.argmax(dim=-1)\n",
    "            output_ids[active_mask, t] = next_tokens\n",
    "            \n",
    "            # Update states for active sequences\n",
    "            hidden[:, active_mask, :] = hidden_step\n",
    "            cell[:, active_mask, :] = cell_step\n",
    "            \n",
    "            # Update which sequences are still active\n",
    "            unfinished[active_mask] = (next_tokens != eos_index)\n",
    "            active_mask = torch.nonzero(unfinished, as_tuple=False).squeeze(-1)\n",
    "            \n",
    "            # Early termination if no active sequences\n",
    "            if active_mask.nelement() == 0:\n",
    "                break\n",
    "        \n",
    "        return output_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6819cc",
   "metadata": {},
   "source": [
    "## BLEU accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_bleu(model, dataloader, english_tokens, device, max_length=50, weights=(0.25, 0.25, 0.25, 0.25)):\n",
    "    model.eval()\n",
    "    references = []  \n",
    "    hypotheses = []  \n",
    "\n",
    "    # Get special token IDs\n",
    "    start_id = english_tokens.get(\"<s>\")\n",
    "    end_id = english_tokens.get(\"</s>\")\n",
    "    \n",
    "    # Create inverse vocabulary for decoding (with fallback for unknown tokens)\n",
    "    inv_trg_vocab = {idx: token for token, idx in english_tokens.items()}\n",
    "    \n",
    "    # Smoothing function for BLEU\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_len, postags in dataloader:\n",
    "            src, src_len = src.to(device), src_len.to(device)\n",
    "            postags = postags.to(device)\n",
    "            \n",
    "            pred_ids = generate(\n",
    "                model,\n",
    "                src=src, \n",
    "                src_length=src_len, \n",
    "                postags=postags,\n",
    "                max_length=max_length,\n",
    "                start_index=start_id,\n",
    "                end_index=end_id\n",
    "            ) \n",
    "\n",
    "            # Process each example in the batch\n",
    "            for i in range(pred_ids.size(0)):\n",
    "                # Remove <s> and get tokens until </s> for reference\n",
    "                ref_raw = trg[i].tolist()\n",
    "                ref_tokens = []\n",
    "                for tok_id in ref_raw:\n",
    "                    if tok_id == start_id:\n",
    "                        continue\n",
    "                    if tok_id == end_id:\n",
    "                        break\n",
    "                    ref_tokens.append(tok_id)\n",
    "                \n",
    "                # Remove </s> and beyond for hypothesis\n",
    "                hyp_raw = pred_ids[i].tolist()\n",
    "                hyp_tokens = []\n",
    "                for tok_id in hyp_raw:\n",
    "                    if tok_id == end_id:\n",
    "                        break\n",
    "                    hyp_tokens.append(tok_id)\n",
    "                \n",
    "                # Convert token IDs to words\n",
    "                ref_words = [inv_trg_vocab.get(idx, \"<unk>\") for idx in ref_tokens]\n",
    "                hyp_words = [inv_trg_vocab.get(idx, \"<unk>\") for idx in hyp_tokens]\n",
    "                \n",
    "                references.append([ref_words])  # Wrap in list for corpus_bleu\n",
    "                hypotheses.append(hyp_words)\n",
    "\n",
    "    # Compute corpus-level BLEU\n",
    "    return corpus_bleu(\n",
    "        list_of_references=references,\n",
    "        hypotheses=hypotheses,\n",
    "        weights=weights,\n",
    "        smoothing_function=smooth_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a63cb",
   "metadata": {},
   "source": [
    "# Tranining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee016b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(40), desc=\"Epochs\"):\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, clip=1)\n",
    "    val_loss = evaluate(model, val_dataloader,criterion, epoch ,True)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1:02}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "    bleu_score = compute_dataset_bleu(model,val_dataloader,train_data.english_tokens,device,val_data.max_length_english)\n",
    "    print(bleu_score)\n",
    "    # scheduler.step(bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68732c0d",
   "metadata": {},
   "source": [
    "## testing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_vocab, postag_vocab, trg_vocab, model, device, max_len=50):\n",
    "    # Tokenize and POS tag the sentence\n",
    "    postagger = FarasaPOSTagger()\n",
    "    sequence = postagger.tag_segments(sentence)\n",
    "    tokens = [item.tokens[0] for item in sequence]\n",
    "    tags = [item.tags[0] for item in sequence]\n",
    "\n",
    "    # Numericalize tokens and tags\n",
    "    numericalized_tokens = (\n",
    "        [src_vocab[\"<s>\"]]\n",
    "        + [src_vocab.get(token, src_vocab[\"<UNK>\"]) for token in tokens]\n",
    "        + [src_vocab[\"</s>\"]]\n",
    "    )\n",
    "    numericalized_tags = (\n",
    "        [postag_vocab[\"<s>\"]]\n",
    "        + [postag_vocab.get(tag, postag_vocab[\"<UNK>\"]) for tag in tags]\n",
    "        + [postag_vocab[\"</s>\"]]\n",
    "    )\n",
    "    \n",
    "    # Convert to tensors\n",
    "    tensor_tokens = torch.tensor(numericalized_tokens).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "    tensor_tags = torch.tensor(numericalized_tags).unsqueeze(0).to(device)      # [1, seq_len]\n",
    "    src_len = torch.tensor([len(numericalized_tokens)]).to(device)\n",
    "    \n",
    "    # Create mask (all True since it's a single non-padded sequence)\n",
    "    mask = torch.ones(1, len(numericalized_tokens), dtype=torch.bool).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        enc_outs_arabic, hidden_arabic, cell_arabic = model.encoder_arabic(tensor_tokens, src_len)\n",
    "        enc_outs_postag, hidden_postag, cell_postag = model.encoder_postag(tensor_tags, src_len)\n",
    "        \n",
    "        # Combine encoder outputs\n",
    "        combined_enc_outs = torch.cat((enc_outs_arabic, enc_outs_postag), dim=2)\n",
    "        \n",
    "        # Combine and project hidden states\n",
    "        hidden = model.enc2dec(torch.cat((hidden_arabic, hidden_postag), dim=2))\n",
    "        cell = model.enc2dec(torch.cat((cell_arabic, cell_postag), dim=2))\n",
    "    \n",
    "    # Initialize with \"<s>\" token\n",
    "    trg_indexes = [trg_vocab[\"<s>\"]]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Use the updated decoder interface\n",
    "            output, hidden, cell, _ = model.decoder(\n",
    "                trg_tensor, \n",
    "                hidden, \n",
    "                cell,\n",
    "                combined_enc_outs,\n",
    "                mask\n",
    "            )\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        # Stop if EOS is generated\n",
    "        if pred_token == trg_vocab[\"</s>\"]:\n",
    "            break\n",
    "    \n",
    "\n",
    "    return trg_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = translate_sentence(\"تعرف على الحزمة الأكثر استخدامًا في جميع ملفات مصدر <ENG>\",train_data.arabic_tokens,train_data.postags\\\n",
    "                         ,train_data.english_tokens,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_trg_vocab = {i: w for w, i in train_data.english_tokens.items() }\n",
    "translated_tokens = [inv_trg_vocab[idx] for idx in out]\n",
    "translated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c32e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score = compute_dataset_bleu(model,test_dataloader,train_data.english_tokens,device,val_data.max_length_english)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
