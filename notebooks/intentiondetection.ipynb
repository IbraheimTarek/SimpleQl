{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3a5b391c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1984601e0d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, random, pathlib, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DATA_FILE = \"../datasets/intention/intent_dataset.json\"\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS     = 20\n",
    "EMB_DIM    = 32\n",
    "HID_DIM    = 32\n",
    "LR         = 5e-3\n",
    "SEED       = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a29bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    \"\"\"Very simple whitespace + lowercase tokenizer.\"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as fp:\n",
    "    records = json.load(fp)\n",
    "\n",
    "# Build vocab\n",
    "tokens = {tok for r in records for tok in tokenize(r[\"sentence\"])}\n",
    "PAD, UNK = \"<pad>\", \"<unk>\"\n",
    "vocab = {PAD: 0, UNK: 1, **{tok: idx + 2 for idx, tok in enumerate(sorted(tokens))}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f84c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numericalise(sentence: str):\n",
    "    return [vocab.get(tok, vocab[UNK]) for tok in tokenize(sentence)]\n",
    "\n",
    "class IntentDS(Dataset):\n",
    "    def __init__(self, rows):  self.rows = rows\n",
    "    def __len__(self):         return len(self.rows)\n",
    "    def __getitem__(self, i):\n",
    "        vec = numericalise(self.rows[i][\"sentence\"])\n",
    "        lbl = float(self.rows[i][\"label\"])\n",
    "        return torch.tensor(vec, dtype=torch.long), torch.tensor(lbl)\n",
    "\n",
    "def collate(batch):\n",
    "    seqs, labels = zip(*batch)\n",
    "    lens = torch.tensor([len(s) for s in seqs])\n",
    "    max_len = max(lens)\n",
    "    pad = torch.full((len(seqs), max_len), vocab[PAD], dtype=torch.long)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        pad[i, :len(seq)] = seq\n",
    "    return pad, lens, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0732454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(records)\n",
    "split = int(0.8 * len(records))\n",
    "train_dl = DataLoader(IntentDS(records[:split]),  BATCH_SIZE, True,  collate_fn=collate)\n",
    "test_dl  = DataLoader(IntentDS(records[split:]), BATCH_SIZE, False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08dafda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMIntent(nn.Module):\n",
    "    def __init__(self, vsz, emb=EMB_DIM, hid=HID_DIM):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vsz, emb, padding_idx=vocab[PAD])\n",
    "        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n",
    "        self.out  = nn.Linear(hid, 1)\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.emb(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "                x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return torch.sigmoid(self.out(h[-1])).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "152477bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMIntent(len(vocab))\n",
    "criterion, optimiser = nn.BCELoss(), optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1288ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dl, train=False):\n",
    "    model.train() if train else model.eval()\n",
    "    tot_loss = tot_ok = tot = 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, lens, y in dl:\n",
    "            if train: optimiser.zero_grad()\n",
    "            p = model(x, lens)\n",
    "            loss = criterion(p, y)\n",
    "            if train:\n",
    "                loss.backward(); optimiser.step()\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "            tot_ok   += ((p >= .5).float() == y).sum().item()\n",
    "            tot      += y.size(0)\n",
    "    return tot_loss / tot, tot_ok / tot\n",
    "\n",
    "\n",
    "def predict_intent(sentence: str):\n",
    "    model.eval()\n",
    "    vec = numericalise(sentence)\n",
    "    lens = torch.tensor([len(vec)])\n",
    "    x = torch.tensor([vec])\n",
    "    with torch.no_grad():\n",
    "        prob = model(x, lens).item()\n",
    "    return (1 if prob >= 0.5 else 0), prob\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7980a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train acc=67.74%  test acc=43.75%\n",
      "Epoch 02: train acc=80.65%  test acc=56.25%\n",
      "Epoch 03: train acc=91.94%  test acc=68.75%\n",
      "Epoch 04: train acc=100.00%  test acc=62.50%\n",
      "Epoch 05: train acc=98.39%  test acc=81.25%\n",
      "Epoch 06: train acc=100.00%  test acc=81.25%\n",
      "Epoch 07: train acc=100.00%  test acc=81.25%\n",
      "Epoch 08: train acc=100.00%  test acc=81.25%\n",
      "Epoch 09: train acc=100.00%  test acc=87.50%\n",
      "Epoch 10: train acc=100.00%  test acc=81.25%\n",
      "Epoch 11: train acc=100.00%  test acc=81.25%\n",
      "Epoch 12: train acc=100.00%  test acc=81.25%\n",
      "Epoch 13: train acc=100.00%  test acc=81.25%\n",
      "Epoch 14: train acc=100.00%  test acc=81.25%\n",
      "Epoch 15: train acc=100.00%  test acc=81.25%\n",
      "Epoch 16: train acc=100.00%  test acc=81.25%\n",
      "Epoch 17: train acc=100.00%  test acc=75.00%\n",
      "Epoch 18: train acc=100.00%  test acc=75.00%\n",
      "Epoch 19: train acc=100.00%  test acc=75.00%\n",
      "Epoch 20: train acc=100.00%  test acc=75.00%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, train=True)\n",
    "    te_loss, te_acc = run_epoch(test_dl,  train=False)\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"train acc={tr_acc:.2%}  test acc={te_acc:.2%}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c44bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test sentence:  don't remove any associated promotional discounts\n",
      "Predicted label: 1 (prob=0.995)\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "test_sentence = \"Please don't delete every temporary table after you finish the analysis.\"\n",
    "pred_label, pred_prob = predict_intent(test_sentence)\n",
    "print(f\"\\nTest sentence: {test_sentence}\\nPredicted label: {pred_label} (prob={pred_prob:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43fbde3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test sentence: How many movies have a popularity of more than 400 but less than 500? Indicate the name of the movies and the highest rating score each movie has received.\n",
      "Predicted label: 0 (prob=0.001)\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"How many movies have a popularity of more than 400 but less than 500? Indicate the name of the movies and the highest rating score each movie has received.\"\n",
    "pred_label, pred_prob = predict_intent( test_sentence)\n",
    "print(f\"\\nTest sentence: {test_sentence}\\nPredicted label: {pred_label} (prob={pred_prob:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
